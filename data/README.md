# Data Directory

‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö ASL Dataset

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á (Simplified)

```
data/
‚îú‚îÄ‚îÄ asl_dataset/           # ‚≠ê Dataset ‡∏´‡∏•‡∏±‡∏Å (‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Kaggle)
‚îÇ   ‚îú‚îÄ‚îÄ a/                # ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ A
‚îÇ   ‚îú‚îÄ‚îÄ b/                # ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ B
‚îÇ   ‚îú‚îÄ‚îÄ ...               # C-Z
‚îÇ   ‚îî‚îÄ‚îÄ 0-9/              # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (optional)
‚îÇ
‚îî‚îÄ‚îÄ README.md             # ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå `raw/` ‡∏´‡∏£‡∏∑‡∏≠ `processed/` ‡∏≠‡∏µ‡∏Å‡∏ï‡πà‡∏≠‡πÑ‡∏õ ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô `asl_dataset/` ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á

---

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Kaggle (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) ‚≠ê

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á kagglehub**

```bash
pip install kagglehub
```

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Kaggle API**

1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà https://www.kaggle.com/settings
2. ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô 'API' ‡∏Ñ‡∏•‡∏¥‡∏Å 'Create New Token'
3. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå `kaggle.json`
4. ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà:
   - **Windows**: `C:\Users\<username>\.kaggle\kaggle.json`
   - **Mac/Linux**: `~/.kaggle/kaggle.json`

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Dataset**

```bash
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
python download_dataset.py

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô
python download_dataset.py --check
```

---

### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 2: ‡πÉ‡∏ä‡πâ Dataset ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß

‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ dataset ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß:

```bash
# ‡∏ß‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô data/asl_dataset/
data/asl_dataset/
‚îú‚îÄ‚îÄ a/
‚îú‚îÄ‚îÄ b/
‚îî‚îÄ‚îÄ ... (‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏≠‡∏∑‡πà‡∏ô‡πÜ)
```

---

## üìä Dataset Information

**‡∏ä‡∏∑‡πà‡∏≠**: ASL Alphabet Dataset  
**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤**: Kaggle - `ayuraj/asl-dataset`  
**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô**: ~2,500+ ‡∏†‡∏≤‡∏û  
**Classes**: 26 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ (A-Z) + 10 ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (0-9, optional)

---

## üîß Configuration

Path ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô `src/config.py`:

```python
class DataConfig:
    DATA_ROOT = "data/"
    DATASET_PATH = "data/asl_dataset"  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
    KAGGLE_DATASET = "ayuraj/asl-dataset"
```

---

## üéØ ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î

```bash
# 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset
python check_dataset.py

# 2. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ train model)
python preprocess_dataset.py

# 3. ‡∏£‡∏±‡∏ô application
streamlit run app.py
```

---

## üìù Scripts ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

| Script | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ |
|--------|----------|
| `download_dataset.py` | ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å Kaggle |
| `check_dataset.py` | ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö dataset |
| `preprocess_dataset.py` | ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• dataset |

---

## üîç Troubleshooting

### ‚ùå "No module named 'kagglehub'"

```bash
pip install kagglehub
```

### ‚ùå "Could not find kaggle.json"

‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Kaggle API ‡∏ï‡∏≤‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô

### ‚ùå "Dataset not found"

```bash
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà
python download_dataset.py

# ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏≤‡∏á dataset ‡πÄ‡∏≠‡∏á‡πÉ‡∏ô data/asl_dataset/
```

---

**‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó**: October 14, 2025  
**‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà**: ‡πÉ‡∏ä‡πâ `asl_dataset/` ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡πÑ‡∏°‡πà‡∏°‡∏µ raw/processed)

### 2. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Dataset

**‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∏‡∏ì‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß!**

```python
# ‡πÉ‡∏ä‡πâ preprocessor ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô landmarks
from src.utils.pytorch_utils.preprocessor import ASLDataPreprocessor
from src.utils.pytorch_utils.data_handler import DataHandler
from sklearn.preprocessing import LabelEncoder

# ‡∏™‡∏£‡πâ‡∏≤‡∏á preprocessor
preprocessor = ASLDataPreprocessor()

# ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• dataset (‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ default path)
X, y = preprocessor.process_dataset(
    dataset_path='data/asl_dataset',  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
    augment=True,
    augment_factor=2,
    filter_alphabet_only=True  # ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ A-Z ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° 0-9
)

# Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
DataHandler.save_processed_data(X, y_encoded, 'data/processed/asl_processed.pkl')
DataHandler.save_label_encoder(le, 'data/processed/label_encoder.pkl')

print(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(X)} samples ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
print(f"‚úÖ {len(set(y))} classes: {sorted(set(y))}")
```

**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:**
- ‡πÉ‡∏ä‡πâ `filter_alphabet_only=True` ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏û‡∏≤‡∏∞ A-Z
- ‡πÉ‡∏ä‡πâ `filter_alphabet_only=False` ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 0-9

### 3. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß

```python
from src.utils.pytorch_utils.data_handler import DataHandler

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
X, y = DataHandler.load_processed_data('data/processed/processed_data.pkl')
label_encoder = DataHandler.load_label_encoder('data/processed/label_encoder.pkl')
```

## üìä ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### Raw Data (‡∏†‡∏≤‡∏û)
- **Format**: .jpg, .png, .jpeg
- **‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥**: 200x200 ‡∏´‡∏£‡∏∑‡∏≠ 224x224 pixels
- **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô**: ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 100 ‡∏†‡∏≤‡∏û‡∏ï‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
- **Background**: ‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢

### Processed Data (Landmarks)
- **Format**: NumPy array
- **Shape**: (n_samples, 63)
  - 21 landmarks √ó 3 coordinates (x, y, z)
- **Normalized**: ‡∏Ñ‡πà‡∏≤ 0-1

## üîß Configuration

‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ paths ‡πÉ‡∏ô `src/config.py`:

```python
class DataConfig:
    DATA_ROOT = "data/"
    DATA_RAW = "data/asl_dataset/"      # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
    DATA_PROCESSED = "data/processed/"
    DATASET_PATH = "data/asl_dataset"   # ‡πÉ‡∏ä‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ
    PROCESSED_DATA_PATH = "data/processed/asl_processed.pkl"
```

## üöÄ Quick Start

**‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:**

```python
from pathlib import Path

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ dataset ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
dataset_path = Path('data/asl_dataset')
letters = sorted([f.name for f in dataset_path.iterdir() if f.is_dir()])
print(f"‡∏û‡∏ö {len(letters)} folders: {letters}")

# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ folder
for letter in letters[:3]:  # ‡πÅ‡∏™‡∏î‡∏á 3 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å
    count = len(list((dataset_path / letter).glob('*.*')))
    print(f"{letter.upper()}: {count} images")
```

**Output ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á:**
```
‡∏û‡∏ö 36 folders: ['0', '1', ..., 'a', 'b', ..., 'z']
A: 70 images
B: 70 images
C: 70 images
```

## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏

- ‚ö†Ô∏è ‡πÑ‡∏ü‡∏•‡πå `.pkl` ‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (100-500 MB)
- üí° ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° `data/raw/` ‡πÅ‡∏•‡∏∞ `data/processed/` ‡πÉ‡∏ô `.gitignore`
- üîÑ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ data augmentation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

## üöÄ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£

```python
from src.utils.pytorch_utils.preprocessor import ASLDataPreprocessor
from src.utils.pytorch_utils.data_handler import DataHandler
from sklearn.preprocessing import LabelEncoder

# 1. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• dataset
preprocessor = ASLDataPreprocessor()
X, y = preprocessor.process_dataset('data/raw/asl_dataset')

# 2. Encode labels
le = LabelEncoder()
y_encoded = le.fit_transform(y)

# 3. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
DataHandler.save_processed_data(X, y_encoded, 'data/processed/processed_data.pkl')
DataHandler.save_label_encoder(le, 'data/processed/label_encoder.pkl')

print(f"‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {len(X)} samples ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
print(f"‚úÖ {len(set(y))} classes: {sorted(set(y))}")
```

---

**‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏î‡∏¢**: ASL Recognition Project  
**‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î**: October 14, 2025
